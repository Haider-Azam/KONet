{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "torchvision.disable_beta_transforms_warning()\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.models import efficientnet_b0,EfficientNet_B0_Weights,densenet121,DenseNet121_Weights\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "import warnings\n",
    "\n",
    "class KONet(torch.nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            m1_ratio=0.6,\n",
    "            m2_ratio=0.4,\n",
    "            m1_dropout=0.1,\n",
    "            m2_dropout=0.3,\n",
    "            n_classes=2\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert m1_ratio+m2_ratio==1\n",
    "        self.n_classes=n_classes\n",
    "        self.m1_ratio=m1_ratio\n",
    "        self.m2_ratio=m2_ratio\n",
    "        self.m1_dropout=m1_dropout\n",
    "        self.m2_dropout=m2_dropout\n",
    "\n",
    "        self.efficient=efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT)\n",
    "        self.efficient.classifier[0]=torch.nn.Dropout(p=self.m1_dropout,inplace=True)\n",
    "        self.efficient.classifier[-1]=torch.nn.Linear(in_features=1280,out_features=self.n_classes)\n",
    "\n",
    "        self.dense=densenet121(weights=DenseNet121_Weights.DEFAULT)\n",
    "        self.dense.classifier=torch.nn.Sequential(torch.nn.Dropout(p=self.m2_dropout,inplace=True),\n",
    "                                            torch.nn.Linear(in_features=1024,out_features=n_classes),\n",
    "                                            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        m1=self.efficient(x)\n",
    "        m2=self.dense(x)\n",
    "        out=self.m1_ratio*m1+self.m2_ratio*m2\n",
    "        return out\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "n_classes=2\n",
    "image_shape=224\n",
    "augmented_dataset_size=4000\n",
    "    \n",
    "path=\"D:\\Osteoporosis detection\\datasets\\Osteoporosis Knee X-ray Dataset\"\n",
    "non_augment_transform=v2.Compose([v2.ToImageTensor(),\n",
    "                       v2.ToDtype(torch.float32),\n",
    "                       v2.Resize((image_shape,image_shape),antialias=True),\n",
    "                       v2.Normalize(mean=[0.5], std=[0.5]),\n",
    "                       ])\n",
    "transforms=v2.Compose([v2.ToImageTensor(),\n",
    "                        v2.ToDtype(torch.float32),\n",
    "                        v2.RandomAffine(degrees=30,shear=30),\n",
    "                        v2.RandomZoomOut(side_range=(1,1.5)),\n",
    "                        v2.Resize((image_shape,image_shape),antialias=True),\n",
    "                        v2.Normalize(mean=[0.5], std=[0.5]),\n",
    "                        ])\n",
    "non_augmented_dataset=torchvision.datasets.ImageFolder(path,transform=non_augment_transform)\n",
    "\n",
    "\n",
    "generator1 = torch.Generator().manual_seed(42)\n",
    "train_split=0.8\n",
    "valid_split=0.1\n",
    "test_split=0.1\n",
    "train_set,valid_set,test_set=torch.utils.data.random_split(non_augmented_dataset, [train_split,valid_split,test_split],\n",
    "                                                                generator=generator1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  efficient\n"
     ]
    }
   ],
   "source": [
    "model_name='efficient'\n",
    "print('Model: ',model_name)\n",
    "#EfficientNetB0 has 16 MBConv layers, freeze till 8th MBConv layer then. Freeze all till before 5th sequential\n",
    "#DenseNet121 has 58 dense layers, freeze till 29th dense layer then. #Till before dense block 3\n",
    "if model_name=='efficient':\n",
    "    model=efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT)\n",
    "    p=0.1\n",
    "    model.classifier[0]=torch.nn.Dropout(p=p,inplace=True)\n",
    "    model.classifier[-1]=torch.nn.Linear(in_features=1280,out_features=n_classes)\n",
    "    frozen_layers=4\n",
    "\n",
    "elif model_name=='dense':\n",
    "    model=densenet121(weights=DenseNet121_Weights.DEFAULT)\n",
    "    p=0.3\n",
    "    model.classifier=torch.nn.Sequential(torch.nn.Dropout(p=p,inplace=True),\n",
    "                                        torch.nn.Linear(in_features=1024,out_features=n_classes),\n",
    "                                        )\n",
    "\n",
    "elif 'mobilenet' in model_name:\n",
    "    print('working')\n",
    "    model=torchvision.models.mobilenet_v3_small(weights='DEFAULT')\n",
    "    model.classifier[3]=torch.nn.Linear(in_features=1024,out_features=n_classes)\n",
    "\n",
    "elif 'conv_next' in model_name:\n",
    "    p=0.3\n",
    "    model=torchvision.models.convnext_tiny(weights='DEFAULT')\n",
    "    model.classifier[2]=torch.nn.Sequential(torch.nn.Dropout(p=p,inplace=True),\n",
    "                                            torch.nn.Linear(in_features=768,out_features=n_classes),\n",
    "                                            )\n",
    "\n",
    "elif model_name=='KONet':\n",
    "    m1_ratio=0.6\n",
    "    m2_ratio=0.4\n",
    "    m1_dropout=0.1\n",
    "    m2_dropout=0.3\n",
    "    model=KONet(m1_ratio=m1_ratio,m2_ratio=m2_ratio,m1_dropout=m1_dropout,m2_dropout=m2_dropout,n_classes=n_classes)\n",
    "\n",
    "model.load_state_dict(torch.load(f\"model/{model_name}best_param.pkl\"))\n",
    "\n",
    "model=model.features\n",
    "#model=model[:4]\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "#Grabs the weights of the final layer in the feature extractor\n",
    "weights = list(model.parameters())[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_sample=test_set.__getitem__(1)[0].unsqueeze(0)\n",
    "osteoporosis_sample=test_set.__getitem__(2)[0].unsqueeze(0)\n",
    "\n",
    "normal_sample = normal_sample.to(device)\n",
    "osteoporosis_sample = osteoporosis_sample.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_output=model(normal_sample)\n",
    "osteoporosis_output=model(osteoporosis_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_heatmap = None\n",
    "osteoporosis_heatmap = None\n",
    "\n",
    "for i in range (0, len(weights)):\n",
    "    normal_map = normal_output[0,i,:,:]\n",
    "    osteoporosis_map = osteoporosis_output[0,i,:,:]\n",
    "\n",
    "    if i == 0:\n",
    "        normal_heatmap = weights[i] * normal_map\n",
    "        osteoporosis_heatmap = weights[i] * osteoporosis_map\n",
    "    else:\n",
    "        normal_heatmap += weights[i] * normal_map\n",
    "        osteoporosis_heatmap += weights[i] * osteoporosis_map\n",
    "\n",
    "normal_heatmap=normal_heatmap.cpu().data.numpy()\n",
    "osteoporosis_heatmap=osteoporosis_heatmap.cpu().data.numpy()\n",
    "\n",
    "normal_heatmap/=np.max(normal_heatmap)\n",
    "osteoporosis_heatmap/=np.max(osteoporosis_heatmap)\n",
    "\n",
    "normal_heatmap=cv2.resize(normal_heatmap,(image_shape,image_shape))\n",
    "osteoporosis_heatmap=cv2.resize(osteoporosis_heatmap,(image_shape,image_shape))\n",
    "\n",
    "normal_heatmap = cv2.applyColorMap(np.uint8(255*normal_heatmap), cv2.COLORMAP_JET)\n",
    "osteoporosis_heatmap = cv2.applyColorMap(np.uint8(255*osteoporosis_heatmap), cv2.COLORMAP_JET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_image=normal_sample.cpu().numpy()[0]\n",
    "normal_image=normal_image.transpose(1,2,0)\n",
    "\n",
    "osteoporosis_image=osteoporosis_sample.cpu().numpy()[0]\n",
    "osteoporosis_image=osteoporosis_image.transpose(1,2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('normal_image.jpg',normal_image)\n",
    "cv2.imwrite('osteoporosis_image.jpg',osteoporosis_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cv2.imwrite(f'normal_heatmap_{model_name}.jpg',normal_image+0.5*normal_heatmap)\n",
    "#cv2.imwrite(f'osteoporosis_heatmap_{model_name}.jpg',osteoporosis_image+0.5*osteoporosis_heatmap)\n",
    "\n",
    "cv2.imwrite(f'normal_heatmap.jpg',normal_image+0.5*normal_heatmap)\n",
    "cv2.imwrite(f'osteoporosis_heatmap.jpg',osteoporosis_image+0.5*osteoporosis_heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
