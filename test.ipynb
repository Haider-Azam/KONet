{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af03825f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "torchvision.disable_beta_transforms_warning()\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.models import efficientnet_b0,EfficientNet_B0_Weights,densenet121,DenseNet121_Weights\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt  \n",
    "import warnings\n",
    "import random\n",
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class KONet(torch.nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            m1_ratio=0.6,\n",
    "            m2_ratio=0.4,\n",
    "            m1_dropout=0.1,\n",
    "            m2_dropout=0.3,\n",
    "            n_classes=2\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert m1_ratio+m2_ratio==1\n",
    "        self.n_classes=n_classes\n",
    "        self.m1_ratio=m1_ratio\n",
    "        self.m2_ratio=m2_ratio\n",
    "        self.m1_dropout=m1_dropout\n",
    "        self.m2_dropout=m2_dropout\n",
    "\n",
    "        self.efficient=efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT)\n",
    "        self.efficient.classifier[0]=torch.nn.Dropout(p=self.m1_dropout,inplace=True)\n",
    "        self.efficient.classifier[-1]=torch.nn.Linear(in_features=1280,out_features=self.n_classes)\n",
    "\n",
    "        self.dense=densenet121(weights=DenseNet121_Weights.DEFAULT)\n",
    "        self.dense.classifier=torch.nn.Sequential(torch.nn.Dropout(p=self.m2_dropout,inplace=True),\n",
    "                                            torch.nn.Linear(in_features=1024,out_features=n_classes),\n",
    "                                            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        m1=self.efficient(x)\n",
    "        m2=self.dense(x)\n",
    "        out=self.m1_ratio*m1+self.m2_ratio*m2\n",
    "        return out\n",
    "    \n",
    "def test(model,dataloader,loss_fn):\n",
    "    model.eval()\n",
    "    loss=0\n",
    "    labels=[]\n",
    "    probabilities=[]\n",
    "    for data,label in tqdm(dataloader):\n",
    "        with torch.no_grad():\n",
    "            data , label=data.to(device) , label.to(device)\n",
    "\n",
    "            output=model(data)\n",
    "            loss+=loss_fn(output , label)\n",
    "            prob=output.softmax(dim=1)\n",
    "            labels.append(label.detach().cpu().numpy())\n",
    "            probabilities.append(prob.detach().cpu().numpy())\n",
    "\n",
    "    labels=np.concatenate(labels,axis=0)\n",
    "    probabilities=np.concatenate(probabilities,axis=0)\n",
    "\n",
    "    loss=loss/len(dataloader)\n",
    "    return loss.item(),labels,probabilities\n",
    "\n",
    "def set_random_seed(seed: int = 2222, deterministic: bool = False):\n",
    "        \"\"\"Set seeds\"\"\"\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)  # type: ignore\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        torch.backends.cudnn.deterministic = deterministic  # type: ignore\n",
    "\n",
    "    \n",
    "def prep_dataset(path,image_shape=224,augmented_dataset_size=4000\n",
    "                 ,train_split=0.8,valid_split=0.1,test_split=0.1):\n",
    "\n",
    "    non_augment_transform=v2.Compose([v2.ToImageTensor(),\n",
    "                        v2.ToDtype(torch.float32),\n",
    "                        v2.Resize((image_shape,image_shape),antialias=True),\n",
    "                        v2.Normalize(mean=[0.5], std=[0.5]),\n",
    "                        ])\n",
    "    transforms=v2.Compose([v2.ToImageTensor(),\n",
    "                        v2.ToDtype(torch.float32),\n",
    "                        v2.RandomAffine(degrees=30,shear=30),\n",
    "                        v2.RandomZoomOut(side_range=(1,1.5)),\n",
    "                        v2.Resize((image_shape,image_shape),antialias=True),\n",
    "                        v2.Normalize(mean=[0.5], std=[0.5]),\n",
    "                        ])\n",
    "    non_augmented_dataset=torchvision.datasets.ImageFolder(path,transform=non_augment_transform)\n",
    "    dataset=torchvision.datasets.ImageFolder(path,transform=transforms)\n",
    "    factor=augmented_dataset_size//len(dataset)\n",
    "\n",
    "    new_dataset=torch.utils.data.ConcatDataset([non_augmented_dataset]+[dataset for _ in range(factor)])\n",
    "    del non_augmented_dataset,dataset\n",
    "\n",
    "    \n",
    "    #dataset=torchvision.datasets.ImageFolder(path,transform=transforms)\n",
    "    generator1 = torch.Generator().manual_seed(42)\n",
    "\n",
    "    #return torch.utils.data.random_split(new_dataset, [train_split,valid_split,test_split],\n",
    "    #                                                            generator=generator1)\n",
    "    return torch.utils.data.random_split(new_dataset, [train_split+valid_split,test_split],\n",
    "                                                                generator=generator1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
