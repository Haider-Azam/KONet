{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "torchvision.disable_beta_transforms_warning()\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.models import efficientnet_b0,EfficientNet_B0_Weights,densenet121,DenseNet121_Weights\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "def set_random_seed(seed: int = 2222, deterministic: bool = False):\n",
    "    \"\"\"Set seeds\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = deterministic  # type: ignore\n",
    "\n",
    "class GradCAM(torch.nn.Module):\n",
    "    def __init__(self,model,target_layer):\n",
    "        super(GradCAM, self).__init__()\n",
    "        \n",
    "        # get the pretrained VGG19 network\n",
    "        self.model = model.eval()\n",
    "        self.target_layer = target_layer\n",
    "        \n",
    "        self.activation = None\n",
    "        self.gradient = None\n",
    "\n",
    "        target_layer.register_forward_hook(self.hook_activation)\n",
    "        target_layer.register_forward_hook(self.hook_gradient)\n",
    "    \n",
    "    def hook_activation(self, module, input, output):\n",
    "        self.activation = output.cpu().detach()\n",
    "\n",
    "    def hook_gradient(self, module, input,output):\n",
    "        def save_grad(grad):\n",
    "            self.gradient = grad.cpu().detach()\n",
    "        output.register_hook(save_grad)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        self.activation = None\n",
    "        self.gradients = None\n",
    "        return self.model(x)\n",
    "    \n",
    "    # method for the gradient extraction\n",
    "    def get_activation_gradient(self):\n",
    "        return self.activation, self.gradient\n",
    "    \n",
    "def save_gradcam(model, sample, class_int, img_name,image_shape):\n",
    "    output=model(sample)\n",
    "\n",
    "    output[:,class_int].backward()\n",
    "\n",
    "    activation,gradient = model.get_activation_gradient()\n",
    "    activation,gradient = activation.squeeze(0), gradient.squeeze(0)\n",
    "\n",
    "    gradient = torch.mean(gradient,dim=[1,2])\n",
    "    activation=activation*gradient.reshape(-1,1,1)\n",
    "\n",
    "    heatmap = activation.mean(dim=0)\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= torch.max(heatmap)\n",
    "    heatmap = heatmap.cpu().detach().data.numpy()\n",
    "    heatmap=cv2.resize(heatmap,(image_shape,image_shape))\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET)\n",
    "\n",
    "    image=sample.cpu().numpy()[0]\n",
    "    image=image.transpose(1,2,0)\n",
    "\n",
    "    cv2.imwrite(img_name,image+0.5*heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "n_classes=2\n",
    "image_shape=224\n",
    "augmented_dataset_size=4000\n",
    "seed=42\n",
    "set_random_seed(seed)\n",
    "path1=\"D:\\Osteoporosis detection\\datasets\\Osteoporosis Knee X-ray Dataset Preprocessed\"\n",
    "path2=\"D:\\Osteoporosis detection\\datasets\\Osteoporosis Knee X-ray modified\\Osteoporosis Knee X-ray Preprocessed\"\n",
    "non_augment_transform=v2.Compose([v2.ToImageTensor(),\n",
    "                       v2.ToDtype(torch.float32),\n",
    "                       v2.Resize((image_shape,image_shape),antialias=True),\n",
    "                       v2.Normalize(mean=[0],std=[1]),\n",
    "                       ])\n",
    "train_split=0.8\n",
    "valid_split=0.1\n",
    "test_split=0.1\n",
    "\n",
    "non_augmented_dataset1=torchvision.datasets.ImageFolder(path1,transform=non_augment_transform)\n",
    "generator1 = torch.Generator().manual_seed(42)\n",
    "_,_,test_set1=torch.utils.data.random_split(non_augmented_dataset1, [train_split,valid_split,test_split],\n",
    "                                                                generator=generator1)\n",
    "\n",
    "non_augmented_dataset2=torchvision.datasets.ImageFolder(path2,transform=non_augment_transform)\n",
    "generator1 = torch.Generator().manual_seed(42)\n",
    "_,_,test_set2=torch.utils.data.random_split(non_augmented_dataset2, [train_split,valid_split,test_split],\n",
    "                                                                generator=generator1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  efficient\n"
     ]
    }
   ],
   "source": [
    "model_name='efficient'\n",
    "print('Model: ',model_name)\n",
    "#EfficientNetB0 has 16 MBConv layers, freeze till 8th MBConv layer then. Freeze all till before 5th sequential\n",
    "#DenseNet121 has 58 dense layers, freeze till 29th dense layer then. #Till before dense block 3\n",
    "if model_name=='efficient':\n",
    "    model=efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT)\n",
    "    p=0.1\n",
    "    model.classifier[0]=torch.nn.Dropout(p=p,inplace=True)\n",
    "    model.classifier[-1]=torch.nn.Linear(in_features=1280,out_features=n_classes)\n",
    "    target_layer = model.features[8][0]\n",
    "    \n",
    "elif model_name=='dense':\n",
    "    model=densenet121(weights=DenseNet121_Weights.DEFAULT)\n",
    "    p=0.3\n",
    "    model.classifier=torch.nn.Sequential(torch.nn.Dropout(p=p,inplace=True),\n",
    "                                        torch.nn.Linear(in_features=1024,out_features=n_classes),\n",
    "                                        )\n",
    "    target_layer = model.features[-2].denselayer16.conv2\n",
    "\n",
    "elif 'mobilenet' in model_name:\n",
    "    model=torchvision.models.mobilenet_v3_small(weights='DEFAULT')\n",
    "    model.classifier[3]=torch.nn.Linear(in_features=1024,out_features=n_classes)\n",
    "    target_layer = model.features[-1][0]\n",
    "\n",
    "elif 'conv_next' in model_name:\n",
    "    p=0.3\n",
    "    model=torchvision.models.convnext_tiny(weights='DEFAULT')\n",
    "    model.classifier[2]=torch.nn.Sequential(torch.nn.Dropout(p=p,inplace=True),\n",
    "                                            torch.nn.Linear(in_features=768,out_features=n_classes),\n",
    "                                            )\n",
    "    target_layer = model.features[-1][-1].block[0]\n",
    "\n",
    "model.load_state_dict(torch.load(f\"model/{model_name}best_param.pkl\"))\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "gradcam_model=GradCAM(model,target_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_sample=test_set.__getitem__(1)[0].unsqueeze(0)\n",
    "osteoporosis_sample=test_set.__getitem__(2)[0].unsqueeze(0)\n",
    "\n",
    "normal_sample = normal_sample.to(device)\n",
    "osteoporosis_sample = osteoporosis_sample.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image=normal_sample.cpu().numpy()[0]\n",
    "image=image.transpose(1,2,0)\n",
    "\n",
    "cv2.imwrite('normal_image.jpg',image)\n",
    "\n",
    "image=osteoporosis_sample.cpu().numpy()[0]\n",
    "image=image.transpose(1,2,0)\n",
    "\n",
    "cv2.imwrite('osteoporosis_image.jpg',image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_int=0\n",
    "img_name = f\"normal_heatmap_{model_name}.jpg\"\n",
    "save_gradcam(gradcam_model,normal_sample,class_int,img_name,image_shape)\n",
    "\n",
    "class_int=1\n",
    "img_name = f\"osteoporosis_heatmap_{model_name}.jpg\"\n",
    "save_gradcam(gradcam_model,osteoporosis_sample,class_int,img_name,image_shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
