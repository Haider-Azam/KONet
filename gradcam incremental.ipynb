{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "torchvision.disable_beta_transforms_warning()\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.models import efficientnet_b0,EfficientNet_B0_Weights,densenet121,DenseNet121_Weights\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "from typing import Tuple, List, Dict\n",
    "\n",
    "def set_random_seed(seed: int = 2222, deterministic: bool = False):\n",
    "    \"\"\"Set seeds\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = deterministic  # type: ignore\n",
    "\n",
    "class CustomImageFolder(torchvision.datasets.ImageFolder):\n",
    "    def find_classes(self, directory: str) -> Tuple[List[str], Dict[str, int]]:\n",
    "        \"\"\"\n",
    "        Override this method to load from setting file instead of scanning directory\n",
    "        \"\"\"\n",
    "        self.map=map\n",
    "        if map is not None:\n",
    "            classes = list(self.map.keys())\n",
    "            classes_to_idx = self.map\n",
    "        else:\n",
    "            classes, classes_to_idx=super().find_classes(directory)\n",
    "        return classes, classes_to_idx\n",
    "    \n",
    "class GradCAM(torch.nn.Module):\n",
    "    def __init__(self,model,target_layer):\n",
    "        super(GradCAM, self).__init__()\n",
    "        \n",
    "        # get the pretrained VGG19 network\n",
    "        self.model = model.eval()\n",
    "        self.target_layer = target_layer\n",
    "        \n",
    "        self.activation = None\n",
    "        self.gradient = None\n",
    "\n",
    "        target_layer.register_forward_hook(self.hook_activation)\n",
    "        target_layer.register_forward_hook(self.hook_gradient)\n",
    "    \n",
    "    def hook_activation(self, module, input, output):\n",
    "        self.activation = output.cpu().detach()\n",
    "\n",
    "    def hook_gradient(self, module, input,output):\n",
    "        def save_grad(grad):\n",
    "            self.gradient = grad.cpu().detach()\n",
    "        output.register_hook(save_grad)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        self.activation = None\n",
    "        self.gradients = None\n",
    "        return self.model(x)\n",
    "    \n",
    "    # method for the gradient extraction\n",
    "    def get_activation_gradient(self):\n",
    "        return self.activation, self.gradient\n",
    "    \n",
    "def prep_dataset(path,image_shape=224,augmented_dataset_size=4000,new_map=None\n",
    "                 ,train_split=0.8,valid_split=0.1,test_split=0.1):\n",
    "    global map\n",
    "    non_augment_transform=v2.Compose([v2.ToImageTensor(),\n",
    "                        v2.ToDtype(torch.float32),\n",
    "                        v2.Resize((image_shape,image_shape),antialias=True),\n",
    "                        #v2.Normalize(mean=[0.5], std=[0.5]),\n",
    "                        ])\n",
    "    transforms=v2.Compose([v2.ToImageTensor(),\n",
    "                        v2.ToDtype(torch.float32),\n",
    "                        v2.RandomAffine(degrees=30,shear=30),\n",
    "                        v2.RandomZoomOut(side_range=(1,1.5)),\n",
    "                        v2.Resize((image_shape,image_shape),antialias=True),\n",
    "                        #v2.Normalize(mean=[0.5], std=[0.5]),\n",
    "                        ])\n",
    "    map=new_map\n",
    "    non_augmented_dataset=CustomImageFolder(path,transform=non_augment_transform)\n",
    "    # dataset=CustomImageFolder(path,transform=transforms)\n",
    "    # factor=augmented_dataset_size//len(dataset)-1\n",
    "\n",
    "    # print(dataset.__getitem__(0)[1])\n",
    "    # print(dataset.class_to_idx)\n",
    "    # new_dataset=torch.utils.data.ConcatDataset([non_augmented_dataset]+[non_augmented_dataset for _ in range(factor)])\n",
    "    # del non_augmented_dataset,dataset\n",
    "\n",
    "    \n",
    "    #dataset=torchvision.datasets.ImageFolder(path,transform=transforms)\n",
    "    generator1 = torch.Generator().manual_seed(42)\n",
    "    return torch.utils.data.random_split(non_augmented_dataset, [train_split+valid_split,test_split],\n",
    "                                                                generator=generator1)\n",
    "\n",
    "def save_gradcam(model, sample, image, class_int, img_name,image_shape):\n",
    "    output=model(sample)\n",
    "\n",
    "    output[:,class_int].backward()\n",
    "\n",
    "    activation,gradient = model.get_activation_gradient()\n",
    "    activation,gradient = activation.squeeze(0), gradient.squeeze(0)\n",
    "\n",
    "\n",
    "    gradient = torch.mean(gradient,dim=[1,2])\n",
    "    activation=activation*gradient.reshape(-1,1,1)\n",
    "\n",
    "    heatmap = activation.mean(dim=0)\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= torch.max(heatmap)\n",
    "    heatmap = heatmap.cpu().detach().data.numpy()\n",
    "    heatmap=cv2.resize(heatmap,(image_shape,image_shape))\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET)\n",
    "\n",
    "    cv2.imwrite(img_name,image+0.5*heatmap)\n",
    "\n",
    "def create_model(model_name,n_classes):\n",
    "    if 'efficient' in model_name:\n",
    "        model=efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT)\n",
    "        p=0.1\n",
    "        model.classifier[0]=torch.nn.Dropout(p=p,inplace=True)\n",
    "        model.classifier[-1]=torch.nn.Linear(in_features=1280,out_features=n_classes)\n",
    "        target_layer = model.features[8][0]\n",
    "        \n",
    "    elif 'dense' in model_name:\n",
    "        model=densenet121(weights=DenseNet121_Weights.DEFAULT)\n",
    "        p=0.3\n",
    "        model.classifier=torch.nn.Sequential(torch.nn.Dropout(p=p,inplace=True),\n",
    "                                            torch.nn.Linear(in_features=1024,out_features=n_classes),\n",
    "                                            )\n",
    "        target_layer = model.features[-2].denselayer16.conv2\n",
    "\n",
    "    elif 'mobilenet' in model_name:\n",
    "        model=torchvision.models.mobilenet_v3_small(weights='DEFAULT')\n",
    "        model.classifier[3]=torch.nn.Linear(in_features=1024,out_features=n_classes)\n",
    "        target_layer = model.features[-1][0]\n",
    "\n",
    "    elif 'conv_next' in model_name:\n",
    "        p=0.3\n",
    "        model=torchvision.models.convnext_tiny(weights='DEFAULT')\n",
    "        model.classifier[2]=torch.nn.Sequential(torch.nn.Dropout(p=p,inplace=True),\n",
    "                                                torch.nn.Linear(in_features=768,out_features=n_classes),\n",
    "                                                )\n",
    "        target_layer = model.features[-1][-1].block[0]\n",
    "\n",
    "    model.load_state_dict(torch.load(f\"model/{model_name}best_param.pkl\"))\n",
    "\n",
    "    \n",
    "        \n",
    "    return model, target_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "n_classes=3\n",
    "image_shape=224\n",
    "augmented_dataset_size=4000\n",
    "seed=42\n",
    "path1='D:\\Osteoporosis detection\\datasets\\Osteoporosis Knee X-ray modified\\Osteoporosis Knee X-ray Preprocessed'\n",
    "path2=\"D:\\Osteoporosis detection\\datasets\\Osteoporosis Knee X-ray only osteopenia Preprocessed\"\n",
    "\n",
    "new_n_classes=3\n",
    "map1={'normal':0,'osteoporosis':2}\n",
    "map2={'osteopenia':1}\n",
    "new_map={**map1, **map2}\n",
    "idx_to_class = {v: k for k, v in new_map.items()}\n",
    "\n",
    "set_random_seed(seed)\n",
    "\n",
    "dataset1,test_set1=prep_dataset(path1,image_shape,augmented_dataset_size,map1)\n",
    "dataset2,test_set2=prep_dataset(path2,image_shape,augmented_dataset_size,map2)\n",
    "\n",
    "test_set = torch.utils.data.ConcatDataset([test_set1, test_set2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  mobilenet_incremental_3_class\n"
     ]
    }
   ],
   "source": [
    "model_name='mobilenet_incremental_3_class'\n",
    "print('Model: ',model_name)\n",
    "#EfficientNetB0 has 16 MBConv layers, freeze till 8th MBConv layer then. Freeze all till before 5th sequential\n",
    "#DenseNet121 has 58 dense layers, freeze till 29th dense layer then. #Till before dense block 3\n",
    "model, target_layer = create_model(model_name,n_classes)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "image_normalizer = v2.Normalize(mean=[0], std=[1])\n",
    "sample_normalizer = v2.Normalize(mean=[0.5], std=[0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified indices: [(4, 1, 0), (7, 1, 0), (18, 2, 1), (20, 0, 1), (27, 0, 1), (28, 2, 1), (29, 2, 1), (31, 2, 1)]\n"
     ]
    }
   ],
   "source": [
    "wrong_indices = []\n",
    "model.eval()\n",
    "os.makedirs('misclassify', exist_ok=True)\n",
    "with torch.no_grad():\n",
    "    for idx in range(len(test_set)):\n",
    "        sample, label = test_set.__getitem__(idx)\n",
    "        image = image_normalizer(sample).cpu().numpy().transpose(1,2,0)\n",
    "        sample = sample_normalizer(sample).unsqueeze(0).to(device)\n",
    "        output = model(sample)\n",
    "        pred = output.argmax(dim=1).item()\n",
    "        if pred != label:\n",
    "            wrong_indices.append((idx, pred, label))\n",
    "            cv2.imwrite(f'misclassify/{idx},{pred},{label}.jpg',image)\n",
    "print(\"Misclassified indices:\", wrong_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('misclassify heatmaps', exist_ok=True)\n",
    "\n",
    "gradcam_model=GradCAM(model,target_layer)\n",
    "selected_samples = [(7, 1, 0), (18, 2, 1), (27, 0, 1)]\n",
    "for idx, pred_class, true_class in selected_samples:\n",
    "    sample=test_set.__getitem__(idx)[0].unsqueeze(0)\n",
    "\n",
    "    image=image_normalizer(sample).cpu().numpy()[0]\n",
    "    image=image.transpose(1,2,0)\n",
    "\n",
    "    cv2.imwrite(f'misclassify heatmaps/Idx {idx} Predicted {idx_to_class[pred_class]} Actual {idx_to_class[true_class]}.jpg',image)\n",
    "\n",
    "    img_name = f'misclassify heatmaps/Idx {idx} Predicted {idx_to_class[pred_class]} Actual {idx_to_class[true_class]} pred heatmap.jpg'\n",
    "    sample = sample_normalizer(sample.to(device))\n",
    "    save_gradcam(gradcam_model,sample,image,pred_class,img_name,image_shape)\n",
    "\n",
    "    img_name = f'misclassify heatmaps/Idx {idx} Predicted {idx_to_class[pred_class]} Actual {idx_to_class[true_class]} actual heatmap.jpg'\n",
    "    sample = sample_normalizer(sample.to(device))\n",
    "    save_gradcam(gradcam_model,sample,image,true_class,img_name,image_shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
